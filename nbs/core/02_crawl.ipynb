{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6fca1b-c8cf-449c-9d5c-d8bb10d890ff",
   "metadata": {},
   "source": [
    "# 02 Crawl Webpages\n",
    "\n",
    "> Crawls all subpages for a given url finding all links to a certain file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d30996-0eaa-4130-8f1d-a8c395d089de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core.02_crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d954f1d-5e1b-44f9-bf9c-86be2ec2d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c2ab3-3206-4809-a60b-d2742f5c5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf1d1d-d0ad-4369-97dc-66aaafa920cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pubcrawler as proj\n",
    "from pubcrawler import const, log, utils, tools\n",
    "import adu_proj.utils as adutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f44640-3683-41de-86da-c08a9064033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import urlparse\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638ec6a-1d84-483a-b050-ab0a58862267",
   "metadata": {},
   "source": [
    "Setup Selenium to drive a headless Chrome browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16993b-fc4f-4f21-85ac-2332584f99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36')\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Necessary for some versions of Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb01c5-102c-4181-9f20-3d53454fafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb44b32-90a0-437c-962a-371aba33e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "visited_urls = set()\n",
    "file_links = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6bd9e-d807-4ace-80bc-ee71b30012f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "url = const.url\n",
    "base_domain = urlparse(url).netloc\n",
    "file_type = const.file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb063aea-bd13-4247-917c-b412d51d59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def scroll_to_bottom(driver, # Selenium driver \n",
    "                     timeout=2\n",
    "                    ):\n",
    "    \"Scroll to the bottom of the webpage to ensure all content is loaded.\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait for the page to load\n",
    "        try:\n",
    "            WebDriverWait(driver, timeout).until(\n",
    "                lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "            )\n",
    "            # Update the last height for next scroll\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        except TimeoutException:\n",
    "            # If no new content is loaded within the timeout, break the loop\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03821f-9840-455a-bec6-a359d9db3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def pubcrawl(url: str, # url to get links for \n",
    "          visited_urls: set, # urls that have already been visited by crawl\n",
    "          file_type: str, # type of file to get ie 'pdf'\n",
    "          file_links: dict, # dictionary of links to files found by crawl\n",
    "          driver, # Selenium webdriver \n",
    "          base_domain: str # base domain for url\n",
    "            ):\n",
    "    \"Get the urls for all files of a specified type from subpages of a url\"\n",
    "    if url in visited_urls:\n",
    "        return\n",
    "    print(url)\n",
    "    visited_urls.add(url)\n",
    "    for attempt in range(2):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            break  # If successful, exit the loop\n",
    "        except Exception as e:\n",
    "            if attempt < 1:  # Only retry once\n",
    "                print(f\"Retrying {url} due to error: {e}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed to access {url} after retrying: {e}\")\n",
    "                return  # Skip to the next URL if both attempts fail\n",
    "    if url == base_domain:\n",
    "        sleep(5)\n",
    "    scroll_to_bottom(driver)  # Scroll to bottom to load everything\n",
    "    links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    hrefs = [link.get_attribute('href') for link in links if link.is_displayed() and link.get_attribute('href') not in visited_urls]\n",
    "    for href in hrefs:\n",
    "        if href and href.endswith(f\".{file_type}\"):\n",
    "            file_links.setdefault(href, {'parent_links': []}).setdefault('parent_links', []).append(url)\n",
    "        elif href and urlparse(href).netloc == base_domain and '#' not in href.split('/')[-1] and '.' not in href.split('/')[-1]:\n",
    "            pubcrawl(href, visited_urls, file_type, file_links, driver, base_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437529b-70e5-4e54-9ac2-f1b2d077b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "print(\"𝔏𝔢𝔱 𝔱𝔥𝔢 𝔠𝔯𝔞𝔴𝔩 𝔠𝔬𝔪𝔪𝔢𝔫𝔠𝔢... 𝔓𝔯𝔬𝔰𝔱! 🍺🍺🍺\")\n",
    "print(\"\\nSites visited:\")\n",
    "pubcrawl(url, visited_urls, file_type, file_links, driver, urlparse(url).netloc)\n",
    "print(\"\\nℭ𝔯𝔞𝔴𝔩 𝔠𝔬𝔪𝔭𝔩𝔢𝔱𝔢 💀💀💀\")\n",
    "print(f\"Visited {len(visited_urls)} webpages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946033e-1166-4114-ae54-61ebf03f9af3",
   "metadata": {},
   "source": [
    "Save found files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa7a25-bcf7-46ba-a748-e979c25069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# pd.DataFrame([{'file_link': key, 'parent_links': file_links[key]['parent_links']} for key in file_links]).to_csv(f'{const.pre_output_path}/files.csv', index=False)\n",
    "with open(f'{const.pre_output_path}/data.json', 'w') as f:\n",
    "    json.dump(file_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91857b91-b788-4b2e-9d0c-fb712f9b85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{const.pre_output_path}/visited_urls.json', 'w') as file:\n",
    "    json.dump(list(visited_urls), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e17d7f-84d1-49da-a248-4fabaafcfdda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
